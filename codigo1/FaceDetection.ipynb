{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\mich2020\\anaconda3\\envs\\facedetec\\lib\\site-packages (from face_recognition) (7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mich2020\\anaconda3\\envs\\facedetec\\lib\\site-packages (from face_recognition) (1.16.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mich2020\\anaconda3\\envs\\facedetec\\lib\\site-packages (from face_recognition) (6.2.0)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Downloading https://files.pythonhosted.org/packages/11/93/ec41d6ef7e769977aa08e49441c52276da27859f12dcbf1c6deb96ce5e9f/dlib-19.22.0.tar.gz (7.4MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.22.0-cp37-cp37m-win_amd64.whl size=3053885 sha256=0224ea79ba66adbca9ddf6ffb88a86172938071a14332f4c18efaf57341830c6\n",
      "  Stored in directory: C:\\Users\\Mich2020\\AppData\\Local\\pip\\Cache\\wheels\\bd\\46\\7c\\deeb33803394006488f2378a9adeae08c65c9560f27a85fbce\n",
      "Successfully built dlib\n",
      "Installing collected packages: face-recognition-models, dlib, face-recognition\n",
      "Successfully installed dlib-19.22.0 face-recognition-1.3.0 face-recognition-models-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'face_recognition'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ageitgey/face_recognition.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!start ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"two_people.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 964, 242, 778), (47, 408, 202, 253)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "\n",
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "pil_image = Image.fromarray(image)\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "    # Make the eyebrows into a nightmare\n",
    "    d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.line(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "    d.line(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "\n",
    "    # Gloss the lips\n",
    "    d.polygon(face_landmarks['top_lip'], fill=(150, 0, 0, 128))\n",
    "    d.polygon(face_landmarks['bottom_lip'], fill=(150, 0, 0, 128))\n",
    "    d.line(face_landmarks['top_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "    d.line(face_landmarks['bottom_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "\n",
    "    # Sparkle the eyes\n",
    "    d.polygon(face_landmarks['left_eye'], fill=(255, 255, 255, 30))\n",
    "    d.polygon(face_landmarks['right_eye'], fill=(255, 255, 255, 30))\n",
    "\n",
    "    # Apply some eyeliner\n",
    "    d.line(face_landmarks['left_eye'] + [face_landmarks['left_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "    d.line(face_landmarks['right_eye'] + [face_landmarks['right_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 142, Left: 349, Bottom: 409, Right: 617\n"
     ]
    }
   ],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "\n",
    "# Find all the faces in the image using the default HOG-based model.\n",
    "# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n",
    "# See also: find_faces_in_picture_cnn.py\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 154, Left: 375, Bottom: 390, Right: 611\n"
     ]
    }
   ],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This is an example of running face recognition on a single image\n",
    "# and drawing a box around each person that was identified.\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\"\n",
    "]\n",
    "\n",
    "# Load an image with an unknown face\n",
    "unknown_image = face_recognition.load_image_file(\"two_people.jpg\")\n",
    "\n",
    "# Find all the faces and face encodings in the unknown image\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n",
    "# See http://pillow.readthedocs.io/ for more about PIL/Pillow\n",
    "pil_image = Image.fromarray(unknown_image)\n",
    "# Create a Pillow ImageDraw Draw instance to draw with\n",
    "draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "# Loop through each face found in the unknown image\n",
    "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "    # See if the face is a match for the known face(s)\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # If a match was found in known_face_encodings, just use the first one.\n",
    "    # if True in matches:\n",
    "    #     first_match_index = matches.index(True)\n",
    "    #     name = known_face_names[first_match_index]\n",
    "\n",
    "    # Or instead, use the known face with the smallest distance to the new face\n",
    "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    if matches[best_match_index]:\n",
    "        name = known_face_names[best_match_index]\n",
    "\n",
    "    # Draw a box around the face using the Pillow module\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    text_width, text_height = draw.textsize(name)\n",
    "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "\n",
    "# Remove the drawing library from memory as per the Pillow docs\n",
    "del draw\n",
    "\n",
    "# Display the resulting image\n",
    "pil_image.show()\n",
    "\n",
    "# You can also save a copy of the new image to disk if you want by uncommenting this line\n",
    "# pil_image.save(\"image_with_boxes.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This is an example of running face recognition on a single image\n",
    "# and drawing a box around each person that was identified.\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "gal_gadot_image = face_recognition.load_image_file(\"gal-gadot.jpg\")\n",
    "gal_gadot_face_encoding = face_recognition.face_encodings(gal_gadot_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding,\n",
    "    gal_gadot_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\",\n",
    "    \"gal gadot\"\n",
    "]\n",
    "\n",
    "# Load an image with an unknown face\n",
    "unknown_image = face_recognition.load_image_file(\"maravilla.jpg\")\n",
    "\n",
    "# Find all the faces and face encodings in the unknown image\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n",
    "# See http://pillow.readthedocs.io/ for more about PIL/Pillow\n",
    "pil_image = Image.fromarray(unknown_image)\n",
    "# Create a Pillow ImageDraw Draw instance to draw with\n",
    "draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "# Loop through each face found in the unknown image\n",
    "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "    # See if the face is a match for the known face(s)\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # If a match was found in known_face_encodings, just use the first one.\n",
    "    # if True in matches:\n",
    "    #     first_match_index = matches.index(True)\n",
    "    #     name = known_face_names[first_match_index]\n",
    "\n",
    "    # Or instead, use the known face with the smallest distance to the new face\n",
    "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    if matches[best_match_index]:\n",
    "        name = known_face_names[best_match_index]\n",
    "\n",
    "    # Draw a box around the face using the Pillow module\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    text_width, text_height = draw.textsize(name)\n",
    "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "\n",
    "# Remove the drawing library from memory as per the Pillow docs\n",
    "del draw\n",
    "\n",
    "# Display the resulting image\n",
    "pil_image.show()\n",
    "\n",
    "# You can also save a copy of the new image to disk if you want by uncommenting this line\n",
    "# pil_image.save(\"image_with_boxes.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceDetect",
   "language": "python",
   "name": "facedetect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
